{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36a12bdd",
   "metadata": {},
   "source": [
    "Making a simulator class that is able to:  \n",
    "\n",
    "A) **Extend an existing HDF5 experiment**  \n",
    "\n",
    "B) **Resume/Stitch an experiment**\n",
    "\n",
    "C) **Start a new experiment with starting conditions that are the same as a previous experiment**  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db878b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import compartment\n",
    "import common\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6db9c7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#A) \n",
    "ammend_type = 'Extend' \n",
    "#copies all the code from a previous HDF file into a new file and then starts from there\n",
    "\n",
    "#B)\n",
    "ammend_type = 'Resume'\n",
    "#copies all the code from a previous HDF file into a new file and then runs to finish the time that is left \n",
    "#considered as resuming an experiment that was messed up previously\n",
    "\n",
    "#C)\n",
    "ammend_type = 'LastValues'\n",
    "# copies only the last time step and starts a new simulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5e4cf31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimulatorFromHDF:\n",
    "    \n",
    "    def __init__(self, old_file_name, new_file_name, ammend_type = 'Extend' ):\n",
    "        \n",
    "        self.file_name = \"C:\\ \" + new_file_name\n",
    "         \n",
    "        \n",
    "        self.num_comps = 0\n",
    "        self.one_percent_t = 0\n",
    "        self.interval_num = 1\n",
    "        self.intervals = 0\n",
    "        self.steps = 0\n",
    "        self.ED_on = True\n",
    "        self.diff_constants = {}\n",
    "        self.static_atpase, self.static_sa = True, True\n",
    "        self.comp_arr, self.ed_arr = [], []\n",
    "        self.external_xflux_setup, self.xflux_setup, self.zflux_setup = True, True, True\n",
    "        self.na_o, self.k_o, self.cl_o, self.x_o, self.z_o, self.osm_o = 0, 0, 0, 0, 0, 0\n",
    "        self.p = 0\n",
    "        self.start_t, self.end_t, self.run_t, self.total_t, self.dt = 0, 0, 0, 0, 0\n",
    "        self.xflux_dict = {}\n",
    "        self.xflux_count = 0\n",
    "        self.xoflux_switch = False\n",
    "        self.xoflux_params = {\"start_t\": 0, \"end_t\": 0, \"xo_conc\": 0, \"zo\": 0}\n",
    "        self.xoflux_setup = True\n",
    "        self.xo_start, self.cl_o_start, self.d_xoflux, self.xo_final, self.xo_flux, self.t_xoflux = 0, 0, 0, 0, 0, 0\n",
    "        self.xoflux_points, self.dt_xoflux, self.xo_alpha, self.xo_beta = 0, 0, 0, 0\n",
    "        self.sim_zflux_params = {\"On\": False}\n",
    "        self.sim_current_params = {\"On\": False}\n",
    "        self.syn_dict = {\"On\": False}\n",
    "        self.hh_on = False\n",
    "        self.hh_t_on = 0\n",
    "        self.hh_comp_num = 0\n",
    "        \n",
    "        if ammend_type == 'Extend':\n",
    "        \n",
    "            #######\n",
    "            # COPYING OLD FILE TO NEW FILE\n",
    "            ######\n",
    "            with h5py.File(self.file_name, mode='w') as hdf_new:\n",
    "\n",
    "                hdf_new.filename \n",
    "                with h5py.File(old_file_name, mode='r') as hdf_old:\n",
    "                    groups = list(hdf_old.keys())\n",
    "                    for _ in groups: \n",
    "                        hdf_old.copy(_,hdf_new)\n",
    "                    hdf_old.close()\n",
    "                \n",
    "                \n",
    "            with h5py.File(self.file_name, mode ='r') as hdf_new:\n",
    "            ##### \n",
    "            # FINDING THE LAST INTERVAL AND USING THAT TO START COMPARTMENT INITIALIZATION\n",
    "                \n",
    "                T = hdf_new.get('TIMING')\n",
    "                total_t = T.get('TOTAL_T')[()]\n",
    "                intervals = T.get('INTERVALS')[()]\n",
    "                dt = T.get(\"DT\")[()]\n",
    "                total_steps = total_t / dt\n",
    "                interval_step = total_steps / intervals\n",
    "                interval_arr = [round(interval_step * i) for i in range(intervals)]\n",
    "             \n",
    "                comps = hdf_new.get(groups[0])\n",
    "                comp_list = list(comps.keys())\n",
    "                for _ in range(len(comp_list)):\n",
    "                    comp = comps.get(comp_list[_])\n",
    "                    try:\n",
    "                        last_interval = 0\n",
    "                        for j in range(len(list(comp.keys()))):\n",
    "                        #dataset = C_group.get(str(interval_arr[j]))\n",
    "                            last_interval += 1\n",
    "                        print(' last interval = ' + str(interval_arr[last_interval]))                                                \n",
    "                    except:\n",
    "                        print(\"-1\")\n",
    "                    last_interval_dataset = comp.get(str(interval_arr[last_interval-1]))[()]                        \n",
    "                    rad = last_interval_dataset[1]\n",
    "                    length = last_interval_dataset[2]\n",
    "                    volume = last_interval_dataset[3]\n",
    "                    na = last_interval_dataset[4]\n",
    "                    k = last_interval_dataset[5]\n",
    "                    cl = last_interval_dataset[6]\n",
    "                    x = last_interval_dataset[7]\n",
    "                    z = last_interval_dataset[8]\n",
    "                    \n",
    "                    first_interval_dataset = comp.get(\"0\")[()]\n",
    "                    start_rad = first_interval_dataset[1]\n",
    "                    start_length = first_interval_dataset[2]\n",
    "                    start_na = first_interval_dataset[4]\n",
    "                    sa_value = 2 *np.pi*start_rad *start_length\n",
    "                    _comp = compartment.Compartment(comp_list[_],radius= rad, length=length, static_sa=True, sa_value=sa_value,hh_on=False)\n",
    "                    _comp.set_ion_properties(na_i=na,k_i = k, cl_i = cl, x_i=x, z_i=z)\n",
    "                    _comp.na_i_start = start_na\n",
    "                    self.comp_arr.append(_comp)\n",
    "                \n",
    "           #####\n",
    "           # Load electrodiffusion data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "143de671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " last interval = 111840000\n",
      " last interval = 111840000\n",
      " last interval = 111840000\n",
      " last interval = 111840000\n",
      " last interval = 111840000\n",
      " last interval = 111840000\n",
      " last interval = 111840000\n",
      " last interval = 111840000\n",
      " last interval = 111840000\n"
     ]
    }
   ],
   "source": [
    "old_file_name = \"T5\"\n",
    "new_file_name = \"Exp3-1_v2_extended\"\n",
    "\n",
    "sim = SimulatorFromHDF(old_file_name,new_file_name, ammend_type ='Extend')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9ba3ee73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.07255831338712135\n",
      "-0.07255832164807695\n",
      "-0.0725583382423531\n",
      "-0.07255836331297334\n",
      "-0.07255839707333714\n",
      "-0.0725584398117038\n",
      "-0.07255849188460797\n",
      "-0.07746371676559007\n",
      "-0.07255854048927202\n"
     ]
    }
   ],
   "source": [
    "for i in sim.comp_arr:\n",
    "    print(i.v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8b915f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
